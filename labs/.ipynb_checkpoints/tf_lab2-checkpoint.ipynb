{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Flow basic : Lab 2\n",
    "### Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Building graph using TF operation\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "# Define variable (not usual var in other code; var in tensorflow or trainerable var)\n",
    "# Put random value in W and b using random_normal\n",
    "W = tf.Variable(tf.random_normal([1]),name='weight') \n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train*W+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost function\n",
    "\\begin{align}\n",
    "\\frac{1}{m}\\sum_{i=1}^m (H(x^{(i)}) - y^{(i)})^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y_train)) #reduce mean make cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "# Here, we use GradientDescent to minimize cost function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 12.3852 W: [-0.58279103] b: [-0.10780926]\n",
      "step: 100 cost: 0.0215501 W: [ 0.82949084] b: [ 0.3875784]\n",
      "step: 200 cost: 0.0133166 W: [ 0.86597264] b: [ 0.30467564]\n",
      "step: 300 cost: 0.00822888 W: [ 0.89464229] b: [ 0.23950273]\n",
      "step: 400 cost: 0.00508493 W: [ 0.91717923] b: [ 0.18827096]\n",
      "step: 500 cost: 0.00314219 W: [ 0.93489534] b: [ 0.1479982]\n",
      "step: 600 cost: 0.00194168 W: [ 0.94882172] b: [ 0.11634009]\n",
      "step: 700 cost: 0.00119985 W: [ 0.95976913] b: [ 0.09145404]\n",
      "step: 800 cost: 0.00074143 W: [ 0.96837503] b: [ 0.07189114]\n",
      "step: 900 cost: 0.000458159 W: [ 0.97513986] b: [ 0.05651295]\n",
      "step: 1000 cost: 0.000283117 W: [ 0.98045766] b: [ 0.0444244]\n",
      "step: 1100 cost: 0.000174946 W: [ 0.98463798] b: [ 0.03492156]\n",
      "step: 1200 cost: 0.000108109 W: [ 0.98792398] b: [ 0.02745158]\n",
      "step: 1300 cost: 6.68022e-05 W: [ 0.99050725] b: [ 0.0215794]\n",
      "step: 1400 cost: 4.12802e-05 W: [ 0.9925378] b: [ 0.01696332]\n",
      "step: 1500 cost: 2.55082e-05 W: [ 0.99413401] b: [ 0.01333474]\n",
      "step: 1600 cost: 1.5763e-05 W: [ 0.99538881] b: [ 0.01048234]\n",
      "step: 1700 cost: 9.74047e-06 W: [ 0.9963752] b: [ 0.00824009]\n",
      "step: 1800 cost: 6.01883e-06 W: [ 0.99715054] b: [ 0.0064775]\n",
      "step: 1900 cost: 3.71972e-06 W: [ 0.99776] b: [ 0.00509201]\n",
      "step: 2000 cost: 2.29863e-06 W: [ 0.9982391] b: [ 0.00400283]\n",
      "step: 2100 cost: 1.42043e-06 W: [ 0.99861574] b: [ 0.00314668]\n",
      "step: 2200 cost: 8.77965e-07 W: [ 0.99891174] b: [ 0.00247371]\n",
      "step: 2300 cost: 5.42476e-07 W: [ 0.99914461] b: [ 0.00194463]\n",
      "step: 2400 cost: 3.35277e-07 W: [ 0.99932742] b: [ 0.00152878]\n",
      "step: 2500 cost: 2.0725e-07 W: [ 0.99947125] b: [ 0.00120189]\n",
      "step: 2600 cost: 1.28098e-07 W: [ 0.9995842] b: [ 0.00094503]\n",
      "step: 2700 cost: 7.91812e-08 W: [ 0.99967301] b: [ 0.00074305]\n",
      "step: 2800 cost: 4.90069e-08 W: [ 0.99974287] b: [ 0.00058433]\n",
      "step: 2900 cost: 3.02988e-08 W: [ 0.99979764] b: [ 0.00045962]\n",
      "step: 3000 cost: 1.87606e-08 W: [ 0.99984092] b: [ 0.00036153]\n",
      "step: 3100 cost: 1.16183e-08 W: [ 0.99987465] b: [ 0.00028453]\n",
      "step: 3200 cost: 7.20548e-09 W: [ 0.99990129] b: [ 0.00022396]\n",
      "step: 3300 cost: 4.45764e-09 W: [ 0.99992228] b: [ 0.00017624]\n",
      "step: 3400 cost: 2.75503e-09 W: [ 0.99993902] b: [ 0.00013866]\n",
      "step: 3500 cost: 1.72253e-09 W: [ 0.99995166] b: [ 0.00010954]\n",
      "step: 3600 cost: 1.06314e-09 W: [ 0.99996221] b: [  8.59217544e-05]\n",
      "step: 3700 cost: 6.60525e-10 W: [ 0.99997002] b: [  6.77963835e-05]\n",
      "step: 3800 cost: 4.14597e-10 W: [ 0.99997622] b: [  5.38695494e-05]\n",
      "step: 3900 cost: 2.52195e-10 W: [ 0.99998164] b: [  4.19764401e-05]\n",
      "step: 4000 cost: 1.52852e-10 W: [ 0.99998569] b: [  3.27019479e-05]\n",
      "step: 4100 cost: 9.33179e-11 W: [ 0.99998868] b: [  2.56876665e-05]\n",
      "step: 4200 cost: 6.02209e-11 W: [ 0.99999094] b: [  2.03781001e-05]\n",
      "step: 4300 cost: 3.83125e-11 W: [ 0.99999267] b: [  1.63543791e-05]\n",
      "step: 4400 cost: 2.5679e-11 W: [ 0.99999398] b: [  1.33304493e-05]\n",
      "step: 4500 cost: 1.80999e-11 W: [ 0.99999499] b: [  1.10392484e-05]\n",
      "step: 4600 cost: 1.27898e-11 W: [ 0.99999571] b: [  9.29640009e-06]\n",
      "step: 4700 cost: 9.59233e-12 W: [ 0.99999624] b: [  7.98032215e-06]\n",
      "step: 4800 cost: 7.35649e-12 W: [ 0.99999666] b: [  7.04014565e-06]\n",
      "step: 4900 cost: 6.08225e-12 W: [ 0.99999708] b: [  6.23429014e-06]\n",
      "step: 5000 cost: 5.27223e-12 W: [ 0.9999972] b: [  5.75189506e-06]\n"
     ]
    }
   ],
   "source": [
    "# 2. Run/update graph and get results (i.e. make sessions)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variable in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(5001):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"step:\",step, \"cost:\",sess.run(cost), \"W:\",sess.run(W), \"b:\",sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our train sets, analytic case should be W : 1 and b : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 23.9605 W: [ 0.03223664] b: [ 0.52536899]\n",
      "step: 500 cost: 0.000502465 W: [ 1.01450372] b: [ 1.04763675]\n",
      "step: 1000 cost: 1.69953e-05 W: [ 1.00266743] b: [ 1.0903697]\n",
      "step: 1500 cost: 5.7518e-07 W: [ 1.00049078] b: [ 1.09822822]\n",
      "step: 2000 cost: 1.9549e-08 W: [ 1.00009048] b: [ 1.09967303]\n",
      "step: 2500 cost: 6.85668e-10 W: [ 1.00001681] b: [ 1.09993899]\n",
      "step: 3000 cost: 7.50447e-11 W: [ 1.00000584] b: [ 1.09997952]\n",
      "step: 3500 cost: 7.50447e-11 W: [ 1.00000584] b: [ 1.09997952]\n",
      "step: 4000 cost: 7.50447e-11 W: [ 1.00000584] b: [ 1.09997952]\n",
      "step: 4500 cost: 7.50447e-11 W: [ 1.00000584] b: [ 1.09997952]\n",
      "step: 5000 cost: 7.50447e-11 W: [ 1.00000584] b: [ 1.09997952]\n"
     ]
    }
   ],
   "source": [
    "# Using placeholder to input value directly\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1]),name='weight') \n",
    "b2 = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "hypothesis2 = X*W2+b2\n",
    "\n",
    "cost2 = tf.reduce_mean(tf.square(hypothesis2-Y)) \n",
    "\n",
    "optimizer2 = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train2 = optimizer2.minimize(cost2)\n",
    "\n",
    "\n",
    "sess2 = tf.Session()\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "\n",
    "# Put multiple values in our session\n",
    "for step in range(5001):\n",
    "    cost_val, W_val, b_val, _ = sess2.run([cost2,W2,b2,train2],feed_dict={X:[1,2,3,4,5],Y:[2.1,3.1,4.1,5.1,6.1]})\n",
    "    if step % 500 == 0:\n",
    "        print(\"step:\",step, \"cost:\",cost_val, \"W:\",W_val, \"b:\",b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.10000849]\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "print(sess2.run(hypothesis2, feed_dict={X:[5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.10000849  5.10000277  6.10000849]\n"
     ]
    }
   ],
   "source": [
    "print(sess2.run(hypothesis2, feed_dict={X:[5,4,5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.10000849  5.10000277]\n",
      " [ 4.09999704  5.10000277]]\n"
     ]
    }
   ],
   "source": [
    "print(sess2.run(hypothesis2, feed_dict={X:[[5,4],[3,4]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
